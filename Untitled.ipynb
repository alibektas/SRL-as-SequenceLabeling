{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/vol/fob-vol2/mi16/bektasal/Desktop/thesis/ThesisDev'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insgesamt 2444\r\n",
      "drwx------ 2 bektasal mi16       5 10. Jun 22:20 .\r\n",
      "drwx------ 9 bektasal mi16      15 10. Jun 22:19 ..\r\n",
      "-rw------- 1 bektasal mi16  239917 10. Jun 22:20 dev.txt\r\n",
      "-rw------- 1 bektasal mi16  237712 10. Jun 22:20 test.txt\r\n",
      "-rw------- 1 bektasal mi16 1943334 10. Jun 22:20 train.txt\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!ls -la ./data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torch.nn.modules.rnn import LSTM\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils as util\n",
    "\n",
    "import flair\n",
    "from flair.embeddings import FlairEmbeddings as FE\n",
    "from flair.data import Sentence \n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os \n",
    "import spacy \n",
    "import numpy as np \n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas\n",
    "\n",
    "import ccformat\n",
    "\n",
    "from semantictagger.dataset import Dataset\n",
    "from semantictagger.paradigms import DIRECTTAG\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import os \n",
    "\n",
    "curdir = pwd\n",
    "from flair.data import Corpus\n",
    "from flair.datasets import ColumnCorpus\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data exist.\n"
     ]
    }
   ],
   "source": [
    "def createcolumncorpusfiles():\n",
    "    train_file = Path(\"./UP_English-EWT/en_ewt-up-train.conllu\")\n",
    "    test_file = Path(\"./UP_English-EWT/en_ewt-up-test.conllu\")\n",
    "    dev_file = Path(\"./UP_English-EWT/en_ewt-up-dev.conllu\")\n",
    "    dataset_train = Dataset(train_file)\n",
    "    dataset_test = Dataset(test_file)\n",
    "    dataset_dev = Dataset(dev_file)\n",
    "\n",
    "    dirtag = DIRECTTAG(2)\n",
    "\n",
    "    ccformat.writecolumncorpus(dataset_train , dirtag, filename=\"train\")\n",
    "    ccformat.writecolumncorpus(dataset_dev , dirtag, filename=\"dev\")\n",
    "    ccformat.writecolumncorpus(dataset_test , dirtag, filename=\"test\")\n",
    "\n",
    "if not os.path.isfile(os.path.join(curdir,\"data\",\"train.txt\")):\n",
    "        print(\"Data not found.\")\n",
    "        createcolumncorpusfiles()\n",
    "else :\n",
    "    print(\"Training data exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-10 22:21:38,579 Reading data from /vol/fob-vol2/mi16/bektasal/Desktop/thesis/ThesisDev/data\n",
      "2021-06-10 22:21:38,580 Train: /vol/fob-vol2/mi16/bektasal/Desktop/thesis/ThesisDev/data/train.txt\n",
      "2021-06-10 22:21:38,581 Dev: /vol/fob-vol2/mi16/bektasal/Desktop/thesis/ThesisDev/data/dev.txt\n",
      "2021-06-10 22:21:38,582 Test: /vol/fob-vol2/mi16/bektasal/Desktop/thesis/ThesisDev/data/test.txt\n"
     ]
    }
   ],
   "source": [
    "# define columns\n",
    "columns = {0: 'text', 1: 'srl'}\n",
    "\n",
    "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
    "corpus: Corpus = ColumnCorpus(os.path.join(curdir,\"data\"),\n",
    "                            columns,\n",
    "                            train_file='train.txt',\n",
    "                            test_file='test.txt',\n",
    "                            dev_file='dev.txt')\n",
    "\n",
    "\n",
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings , ELMoEmbeddings\n",
    "\n",
    "tag_type = 'srl'\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "\n",
    "# 4. initialize embeddings\n",
    "embedding_types = [\n",
    "\n",
    "    ELMoEmbeddings('original'),\n",
    "\n",
    "                # comment in this line to use character embeddings\n",
    "                    # CharacterEmbeddings(),\n",
    "\n",
    "                        # comment in these lines to use flair embeddings\n",
    "                            # FlairEmbeddings('news-forward'),\n",
    "                                # FlairEmbeddings('news-backward'),\n",
    "    ]\n",
    "\n",
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "\n",
    "# 5. initialize sequence tagger\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "tagger: SequenceTagger = SequenceTagger(hidden_size=512,\n",
    "        embeddings=embeddings,\n",
    "        tag_dictionary=tag_dictionary , \n",
    "        use_crf=False)\n",
    "    \n",
    "# 6. initialize trainer\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, main.corpus)\n",
    "# 7. start training\n",
    "trainer.train(os.path.join(curdir,\"modelout\"),\n",
    "                      learning_rate=0.1,\n",
    "                    mini_batch_size=32,\n",
    "                    embeddings_storage_mode=\"gpu\",\n",
    "                     max_epochs=150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not SList",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ff67c82c21d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtagger\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mSequenceTagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequenceTagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpwd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"modelout/final-model.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/thesis/lib64/python3.6/posixpath.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mdiscarded\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mAn\u001b[0m \u001b[0mempty\u001b[0m \u001b[0mlast\u001b[0m \u001b[0mpart\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpath\u001b[0m \u001b[0mthat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     ends with a separator.\"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_sep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not SList"
     ]
    }
   ],
   "source": [
    "from flair.models import SequenceTagger\n",
    "from os.path import join\n",
    "\n",
    "tagger : SequenceTagger = SequenceTagger.load(join(pwd,\"modelout/final-model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insgesamt 927685\r\n",
      "-rw------- 1 bektasal mi16 474044045 11. Jun 04:10 best-model.pt\r\n",
      "-rw------- 1 bektasal mi16    297663 11. Jun 04:29 dev.tsv\r\n",
      "-rw------- 1 bektasal mi16 474044045 11. Jun 04:29 final-model.pt\r\n",
      "-rw------- 1 bektasal mi16      7182 11. Jun 04:29 loss.tsv\r\n",
      "-rw------- 1 bektasal mi16    294002 11. Jun 04:29 test.tsv\r\n",
      "-rw------- 1 bektasal mi16    164011 11. Jun 04:29 training.log\r\n",
      "-rw------- 1 bektasal mi16         0 11. Jun 02:00 weights.txt\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!ls -l ./modelout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
